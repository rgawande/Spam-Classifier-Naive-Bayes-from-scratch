# Spam-Classifier-Naive-Bayes-from-scratch

So our main task was to implement the Naive Bayes classifier to determine whether the given mail is a spam or not. We first read all the mails from training set seperately as spam and not spam. Then we calculated the spam probability which is ratio of no of spam mails to total no of mails. Similarly not spam probability was also calculated. After that, we split the mails to get the bag of words and counted the occurences of each word in spam mails as well as in not spam mails. From the word count, we calculated the probability of word given spam & probability of word given not spam. Thus, at the end of the training we had one dictionary with probability of word given spam & one dictionary with probability of word given not spam respectively and also the values of spam probability and not spam probability.

Now, we read all the testing mails and collected everthing in a single string. Then we split it to get the bag of words for testing mails. In each iteration, we multiplied the word given spam probability each time for every word and the when all words were done for one email, we multiplied the spam probabilty at the end. Same thing was done for the not spam probability. If the spam given word probability was greater than the not spam given word probability, then it is labelled as spam, else its labelled as not spam.

One problem we faced was when a new word came in testing mail, and it was not present in the bag of words we got from the training, it was giving a key error because it was not present in any dictionary of probabilities. To handle that, we assigned the fixed equal value of 0.5 to both word given spam probability and word given ham probability. The other problem we faced was as the value of probabilities were too low and we were multiplying it, it was resulting in more low value which made our model biased towards one label and resulting in very low accuracy. So we handled this by taking log values and adding it instead of multiplying the probabilities. This resolved the problem and gave a significant increase in accuracy. We also tried to filter the words we were considering while training by removing special characters and all the words above certain length but then it was reducing our accuracy because those special characters and long web links were mostly part of spam emails. So then we removed all the filtering and took all the words available in training mails. Lastly the implementation was too slow because we were using os.walk so it was taking too much time just to read emails, hence we switched to os.listdir which made the process like 5x faster.
